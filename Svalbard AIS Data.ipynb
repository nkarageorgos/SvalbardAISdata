{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f736916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "url = \"https://kystdatahuset.no/ws/api/ais/positions/within-geom-time\"\n",
    "headers = {\n",
    "    \"Accept\": \"text/plain\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "start_date = datetime.strptime(\"2021-07-01T00:00:00\", \"%Y-%m-%dT%H:%M:%S\")\n",
    "end_date = datetime.strptime(\"2022-03-01T00:00:00\", \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# Define the interval (1 day in this case)\n",
    "interval = 1\n",
    "\n",
    "intervals = []\n",
    "current_start_date = start_date\n",
    "while current_start_date < end_date:\n",
    "    current_end_date = min(current_start_date + timedelta(days=interval), end_date)\n",
    "    intervals.append((current_start_date, current_end_date))\n",
    "    current_start_date = current_end_date\n",
    "\n",
    "# Make requests for each interval and save responses to separate json files\n",
    "for start, end in intervals:\n",
    "    payload = {\n",
    "        \"geom\": \"POLYGON((17.158265 76.77251,17.158265 79.45649,7.910835 79.45649,7.910835 76.77251,17.158265 76.77251))\",\n",
    "        \"start\": start.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"end\": end.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"minSpeed\": 0.0\n",
    "    }\n",
    "    \n",
    "    json_data = json.dumps(payload)\n",
    "    response = requests.post(url, headers=headers, data=json_data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        file_name = f'ais_data_{start.strftime(\"%Y%m%d\")}_to_{end.strftime(\"%Y%m%d\")}.json'\n",
    "        \n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(response.json(), f)\n",
    "        \n",
    "        print(f\"Data for period {start} to {end} successfully written to {file_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for period {start} to {end}. Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ac169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI in Svalbard\n",
    "import folium\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "coordinates = [(17.158265, 76.77251), (17.158265, 79.45649), (7.910835, 79.45649), (7.910835, 76.77251), (16.558265, 76.77251)]\n",
    "\n",
    "polygon = Polygon(coordinates)\n",
    "\n",
    "m = folium.Map(location=[sum(y for _, y in coordinates) / len(coordinates), \n",
    "                          sum(x for x, _ in coordinates) / len(coordinates)], zoom_start=8)\n",
    "\n",
    "folium.Polygon(locations=[list(coord)[::-1] for coord in polygon.exterior.coords],\n",
    "               color='blue', \n",
    "               fill=True,\n",
    "               fill_color='blue').add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m.save('polygon_map.html')\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine previous json files into a common excel file\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "directory = \".\"\n",
    "\n",
    "json_files = glob.glob(f\"{directory}/ais_data_*.json\")\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "column_names = [\n",
    "    \"mmsi\",\n",
    "    \"date time utc\",\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"course over ground\",\n",
    "    \"speed over ground\",\n",
    "    \"AIS message number\",\n",
    "    \"calc_speed\",\n",
    "    \"seconds to previous point\",\n",
    "    \"distance to previous point\"\n",
    "]\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    data_section = data['data']\n",
    "    df = pd.DataFrame(data_section, columns=column_names)\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "output_excel_file = \"ais_data_split.xlsx\"\n",
    "\n",
    "# Excel row limit\n",
    "row_limit = 1048576\n",
    "\n",
    "with pd.ExcelWriter(output_excel_file, engine='xlsxwriter') as writer:\n",
    "    start_row = 0\n",
    "    for start in range(0, combined_df.shape[0], row_limit):\n",
    "        end = min(start + row_limit, combined_df.shape[0])\n",
    "        combined_df.iloc[start:end].to_excel(writer, index=False, sheet_name=f'Sheet{start//row_limit + 1}')\n",
    "        \n",
    "print(f\"Data from all files has been successfully combined and saved to {output_excel_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "\n",
    "def split_on_duration(group, min_duration=pd.Timedelta(minutes=10), max_duration=pd.Timedelta(hours=12)):\n",
    "    group['gap'] = group['date time utc'].diff() > pd.Timedelta(minutes=45)\n",
    "    group['split_id'] = group['gap'].cumsum()\n",
    "    segments = []\n",
    "    \n",
    "    for _, g in group.groupby('split_id'):\n",
    "        # Check duration and split further if necessary\n",
    "        duration = g['date time utc'].max() - g['date time utc'].min()\n",
    "        if duration < min_duration:\n",
    "            continue  # Skip trajectories that are too short\n",
    "        while duration > max_duration:\n",
    "            # Split trajectory at the maximum duration limit\n",
    "            max_time = g['date time utc'].min() + max_duration\n",
    "            segment = g[g['date time utc'] <= max_time]\n",
    "            segments.append(segment)\n",
    "            g = g[g['date time utc'] > max_time]\n",
    "            duration = g['date time utc'].max() - g['date time utc'].min()\n",
    "        segments.append(g)  # Append the remaining segment if any\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def process_trajectory(trajectory):\n",
    "    if len(trajectory) > 360:\n",
    "        trajectory = trajectory.iloc[::len(trajectory)//360]\n",
    "    trajectory = trajectory.set_index('date time utc').resample('2T').mean().interpolate()\n",
    "    return trajectory.reset_index()\n",
    "\n",
    "def filter_trajectory_by_date(trajectory, start_date, end_date):\n",
    "    \"\"\"Filter the trajectory DataFrame to only include data between start_date and end_date.\"\"\"\n",
    "    return trajectory[(trajectory['date time utc'] >= start_date) & (trajectory['date time utc'] <= end_date)]\n",
    "\n",
    "def process_all_sheets(excel_path, start_date, end_date):\n",
    "    xls = pd.ExcelFile(excel_path)\n",
    "    trajectories_by_mmsi = {}\n",
    "\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        ais_data = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        ais_data['date time utc'] = pd.to_datetime(ais_data['date time utc'])\n",
    "        ais_data.sort_values(['mmsi', 'date time utc'], inplace=True)\n",
    "\n",
    "        for mmsi, group in ais_data.groupby('mmsi'):\n",
    "            split_trajectories = split_on_duration(group)\n",
    "            processed_trajectories = [process_trajectory(traj) for traj in split_trajectories]\n",
    "            # Filter trajectories by date\n",
    "            filtered_trajectories = [filter_trajectory_by_date(traj, start_date, end_date) for traj in processed_trajectories]\n",
    "            filtered_trajectories = [traj for traj in filtered_trajectories if not traj.empty]\n",
    "\n",
    "            if mmsi in trajectories_by_mmsi:\n",
    "                trajectories_by_mmsi[mmsi].extend(filtered_trajectories)\n",
    "            else:\n",
    "                trajectories_by_mmsi[mmsi] = filtered_trajectories\n",
    "\n",
    "    return trajectories_by_mmsi\n",
    "\n",
    "# Define the date range\n",
    "start_date = pd.Timestamp('2021-07-01')\n",
    "end_date = pd.Timestamp('2022-03-01')\n",
    "\n",
    "excel_path = 'ais_data_split.xlsx'  \n",
    "trajectories_by_mmsi = process_all_sheets(excel_path, start_date, end_date)\n",
    "\n",
    "# Example: Print a specific trajectory for an MMSI of interest\n",
    "mmsi_of_interest = 257524500  \n",
    "if mmsi_of_interest in trajectories_by_mmsi and trajectories_by_mmsi[mmsi_of_interest]:\n",
    "    print(trajectories_by_mmsi[mmsi_of_interest][0])  \n",
    "else:\n",
    "    print(\"No trajectories found for this MMSI.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c37679",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('trajectories_by_mmsi.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Iterate through each MMSI's trajectories to save them in separate sheets\n",
    "for mmsi, trajectories in trajectories_by_mmsi.items():\n",
    "    for i, trajectory in enumerate(trajectories):\n",
    "        sheet_name = f'MMSI_{mmsi}_Traj_{i+1}'\n",
    "        # Ensure the sheet_name is not longer than 31 characters\n",
    "        sheet_name = sheet_name[:31]\n",
    "        trajectory.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points \n",
    "    on the earth (specified in decimal degrees).\n",
    "    \"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371 # Radius of Earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "def calculate_distance(trajectory):\n",
    "    distances = [haversine(lat1, lon1, lat2, lon2) for (lat1, lon1), (lat2, lon2) \n",
    "                 in zip(trajectory[['latitude', 'longitude']].values[:-1], \n",
    "                         trajectory[['latitude', 'longitude']].values[1:])]\n",
    "    return sum(distances)\n",
    "\n",
    "def calculate_duration(trajectory):\n",
    "    start_time = trajectory['date time utc'].iloc[0]\n",
    "    end_time = trajectory['date time utc'].iloc[-1]\n",
    "    return (end_time - start_time) / pd.Timedelta(hours=1)\n",
    "\n",
    "trajectory_durations = []\n",
    "distances_covered = []\n",
    "average_speeds = []\n",
    "\n",
    "for mmsi, trajectories in trajectories_by_mmsi.items():\n",
    "    for trajectory in trajectories:\n",
    "        duration = calculate_duration(trajectory)\n",
    "        distance = calculate_distance(trajectory)\n",
    "        # Store duration and distance\n",
    "        trajectory_durations.append(duration)\n",
    "        distances_covered.append(distance)\n",
    "        # Calculate and store average speed if duration is not zero\n",
    "        if duration > 0:\n",
    "            average_speeds.append(distance / duration)\n",
    "        else:\n",
    "            average_speeds.append(0)\n",
    "\n",
    "mean_duration = np.mean(trajectory_durations)\n",
    "mean_distance_covered = np.mean(distances_covered)\n",
    "mean_average_speed = np.mean(average_speeds)\n",
    "\n",
    "print(f\"Mean duration of trajectories: {mean_duration:.2f} hours\")\n",
    "print(f\"Mean distance covered per trajectory: {mean_distance_covered:.2f} km\")\n",
    "print(f\"Mean average speed per trajectory: {mean_average_speed:.2f} km/h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of Trajectories' Durations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.hist(trajectory_durations, bins=30, alpha=0.75, color='royalblue', edgecolor='black')\n",
    "\n",
    "plt.title('Distribution of Trajectory Durations', fontsize=18)\n",
    "plt.xlabel('Duration (Hours)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f271a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format trajectories into a pickle file\n",
    "file_path = 'trajectories_by_mmsi.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "all_trajectories = {}\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = pd.read_excel(xls, sheet_name)\n",
    "    \n",
    "    trajectory_info = {\n",
    "        'mmsi': df['mmsi'].iloc[0],\n",
    "        'track_length': len(df),\n",
    "        'lat': df['latitude'].tolist(),\n",
    "        'lon': df['longitude'].tolist(),\n",
    "        'speed': df['speed over ground'].tolist(),\n",
    "        'course': df['course over ground'].tolist(),\n",
    "        'timestamp': pd.to_datetime(df['date time utc']).astype(int) / 10**9  # Convert to UNIX timestamp\n",
    "    }\n",
    "    \n",
    "    # Use sheet name or MMSI as the dictionary key\n",
    "    all_trajectories[sheet_name] = trajectory_info\n",
    "\n",
    "pd.to_pickle(all_trajectories, 'formatted_trajectories.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22054340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data from pickle file\n",
    "all_trajectories = pd.read_pickle('formatted_trajectories.pkl')\n",
    "\n",
    "def print_dataset(data):\n",
    "    # Iterate through the dictionary and print key details\n",
    "    for key, value in data.items():\n",
    "        print(f\"Trajectory: {key}\")\n",
    "        print(f\"MMSI: {value['mmsi']}\")\n",
    "        print(f\"Track Length: {value['track_length']}\")\n",
    "        print(f\"Latitudes: {value['lat'][:5]}\")  # Print first 5 latitudes for brevity\n",
    "        print(f\"Longitudes: {value['lon'][:5]}\")  # Print first 5 longitudes\n",
    "        print(f\"Speeds: {value['speed'][:5]}\")  \n",
    "        print(f\"Courses: {value['course'][:5]}\")  \n",
    "        print(f\"Timestamps: {value['timestamp'][:5]}\")  \n",
    "        print(\"\\n\")  \n",
    "print_dataset(all_trajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Plotting some trajectories (can adjust time and mmsis)\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def plot_ship_trajectories_within_polygon(excel_path, mmsi_list, polygon_wkt, start_date, end_date):\n",
    "    area_polygon = gpd.GeoSeries.from_wkt([polygon_wkt])\n",
    "    area_polygon.crs = \"EPSG:4326\"\n",
    "    \n",
    "    area_polygon = area_polygon.to_crs(epsg=3857)\n",
    "    \n",
    "    minx, miny, maxx, maxy = area_polygon.total_bounds\n",
    "    \n",
    "    xl = pd.ExcelFile(excel_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    for mmsi in mmsi_list:\n",
    "        sheets_for_mmsi = [sheet_name for sheet_name in xl.sheet_names if str(mmsi) in sheet_name]\n",
    "\n",
    "        for sheet_name in sheets_for_mmsi:\n",
    "            trajectory_df = xl.parse(sheet_name)\n",
    "            trajectory_df['date time utc'] = pd.to_datetime(trajectory_df['date time utc'])\n",
    "            trajectory_df = trajectory_df[(trajectory_df['date time utc'] >= start_date) & (trajectory_df['date time utc'] <= end_date)]\n",
    "\n",
    "            if not trajectory_df.empty:\n",
    "                gdf = gpd.GeoDataFrame(\n",
    "                    trajectory_df, \n",
    "                    geometry=gpd.points_from_xy(trajectory_df['longitude'], trajectory_df['latitude'])\n",
    "                )\n",
    "                \n",
    "                gdf.crs = \"EPSG:4326\"\n",
    "                \n",
    "                gdf = gdf.to_crs(epsg=3857)\n",
    "                \n",
    "            \n",
    "                gdf.plot(ax=ax, marker='o', markersize=5, label=sheet_name, linewidth=0.1)\n",
    "\n",
    "    ax.set_xlim(minx, maxx)\n",
    "    ax.set_ylim(miny, maxy)\n",
    "\n",
    "    ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Usage example with date filtering\n",
    "excel_path = 'trajectories_by_mmsi.xlsx' \n",
    "mmsi_list =['257301000', '257471500', '257489000', '273424080', '273425330', '273428090', '273428880', '273430750', '273431310', '273841710', '273845800', '518935000'] # Example MMSI numbers\n",
    "polygon_wkt = \"POLYGON((17.158265 76.77251,17.158265 79.45649,7.910835 79.45649,7.910835 76.77251,17.158265 76.77251))\"\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-02-08'\n",
    "plot_ship_trajectories_within_polygon(excel_path, mmsi_list, polygon_wkt, start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Plotting only the abnormal trajectory on 7 Jan 2022\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def plot_ship_trajectories_within_polygon(excel_path, mmsi_list, polygon_wkt, start_date, end_date):\n",
    "    area_polygon = gpd.GeoSeries.from_wkt([polygon_wkt])\n",
    "    area_polygon.crs = \"EPSG:4326\"\n",
    "    \n",
    "    area_polygon = area_polygon.to_crs(epsg=3857)\n",
    "    \n",
    "    minx, miny, maxx, maxy = area_polygon.total_bounds\n",
    "    \n",
    "    xl = pd.ExcelFile(excel_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    for mmsi in mmsi_list:\n",
    "        sheets_for_mmsi = [sheet_name for sheet_name in xl.sheet_names if str(mmsi) in sheet_name]\n",
    "\n",
    "        for sheet_name in sheets_for_mmsi:\n",
    "            trajectory_df = xl.parse(sheet_name)\n",
    "            trajectory_df['date time utc'] = pd.to_datetime(trajectory_df['date time utc'])\n",
    "            trajectory_df = trajectory_df[(trajectory_df['date time utc'] >= start_date) & (trajectory_df['date time utc'] <= end_date)]\n",
    "\n",
    "            if not trajectory_df.empty:\n",
    "                gdf = gpd.GeoDataFrame(\n",
    "                    trajectory_df, \n",
    "                    geometry=gpd.points_from_xy(trajectory_df['longitude'], trajectory_df['latitude'])\n",
    "                )\n",
    "                \n",
    "                gdf.crs = \"EPSG:4326\"\n",
    "                \n",
    "                gdf = gdf.to_crs(epsg=3857)\n",
    "                \n",
    "            \n",
    "                gdf.plot(ax=ax, marker='o', markersize=5, label=sheet_name, linewidth=0.1)\n",
    "\n",
    "    ax.set_xlim(minx, maxx)\n",
    "    ax.set_ylim(miny, maxy)\n",
    "\n",
    "    ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Usage example with date filtering\n",
    "excel_path = 'trajectories_by_mmsi.xlsx' \n",
    "mmsi_list = ['273418680']\n",
    "polygon_wkt = \"POLYGON((17.158265 76.77251,17.158265 79.45649,7.910835 79.45649,7.910835 76.77251,17.158265 76.77251))\"\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-02-08'\n",
    "plot_ship_trajectories_within_polygon(excel_path, mmsi_list, polygon_wkt, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all the mmsi \n",
    "total_trajectories = sum(len(trajectories) for trajectories in trajectories_by_mmsi.values())\n",
    "trajectories_per_mmsi = {mmsi: len(trajectories) for mmsi, trajectories in trajectories_by_mmsi.items()}\n",
    "\n",
    "total_trajectories, trajectories_per_mmsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing ship types for every MMSI\n",
    "full_ship_data = [\n",
    "    (211336220, \"Tanker\"), (215753000, \"Yacht\"), (219001522, \"Fishing Vessel\"),\n",
    "    (228092600, \"Research Vessel\"), (246337000, \"Passenger Ship\"), (257013250, \"Other Type\"),\n",
    "    (257019000, \"Patrol Vessel\"), (257039490, \"Cargo\"), (257051200, \"Patrol Vessel\"),\n",
    "    (257052200, \"Patrol Vessel\"), (257067270, \"Patrol Vessel\"), (257073260, \"Other Type\"),\n",
    "    (257088040, \"Other Type\"), (257096620, \"Passenger Ship\"), (257153500, \"Fishing Vessel\"),\n",
    "    (257230500, \"Research Vessel\"), (257275000, \"Research Vessel\"), (257301000, \"Cargo\"),\n",
    "    (257471500, \"Research Vessel\"), (257524500, \"Fishing Vessel\"), (257564000, \"Supply Ship\"),\n",
    "    (257582600, \"Fishing Vessel\"), (257620800, \"Pleasure Craft\"), (257677000, \"Tanker\"),\n",
    "    (257729800, \"HSC\"), (257785000, \"Cargo\"), (258072000, \"Supply Ship\"),\n",
    "    (258150000, \"Lighthouse Vessel\"), (258156500, \"Other Type\"), (258330730, \"Other Type\"),\n",
    "    (258430000, \"Tanker\"), (259040000, \"Patrol Vessel\"), (259050000, \"Patrol Vessel\"),\n",
    "    (259109000, \"Fishing Vessel\"), (259255000, \"Cargo\"), (259317000, \"Patrol Vessel\"),\n",
    "    (261000150, \"Research Vessel\"), (273219900, \"Cargo\"), (273251100, \"Cargo\"),\n",
    "    (273312270, \"Fishing Vessel\"), (273326830, \"Fishing Vessel\"), (273332880, \"Fishing Vessel\"),\n",
    "    (273337950, \"Cargo\"), (273350610, \"Fishing Vessel\"), (273398180, \"Fishing Vessel\"),\n",
    "    (273448120, \"Fishing Vessel\"), (273451570, \"Fishing Vessel\"), (273514800, \"Fishing Vessel\"),\n",
    "    (273523100, \"Fishing Vessel\"), (273842800, \"Fishing Vessel\"), (352842000, \"Passenger Ship\"),\n",
    "    (518100276, \"Yacht\"), (518935000, \"Other Type\"), (941004593, \"Other Type\"),\n",
    "    (941004628, \"Other Type\"), (941213368, \"Other Type\"), (982575640, \"Other Type\"),\n",
    "    (982575641, \"Other Type\"), (247405400, \"Research Vessel\"), (248290000, \"Resolution 18 ship\"),\n",
    "    (250005461, \"Cargo\"), (257042110, \"Other Type\"), (257281000, \"Fishing Vessel\"),\n",
    "    (257612000, \"Cargo\"), (257798800, \"Cargo\"), (257939500, \"Fishing Vessel\"),\n",
    "    (257958900, \"Pilot\"), (258168000, \"Other Type\"), (261099070, \"Port tender\"),\n",
    "    (265182000, \"Ice breaker\"), (273212100, \"Fishing Vessel\"), (273384970, \"Cargo\"),\n",
    "    (273411400, \"Research Vessel\"), (273421520, \"Fishing Vessel\"), (273432030, \"Cargo\"),\n",
    "    (273433220, \"Fishing Vessel\"), (273447010, \"Fishing Vessel\"), (273450850, \"Fishing Vessel\"),\n",
    "    (273546000, \"Other Type\"), (276806000, \"Fishing Vessel\"), (276850000, \"Sailing Vessel\"),\n",
    "    (952570116, \"Other Type\"), (246837000, \"Cargo\"), (257029990, \"Other Type\"),\n",
    "    (257088070, \"Passenger Ship\"), (257113000, \"Cargo\"), (257139000, \"Fishing Vessel\"),\n",
    "    (257193000, \"Fishing Vessel\"), (257489000, \"Fishing Vessel\"), (257702000, \"Tanker\"),\n",
    "    (259247000, \"Fishing Vessel\"), (261208000, \"Research Vessel\"), (273213500, \"Fishing Vessel\"),\n",
    "    (273218900, \"Fishing Vessel\"), (273313950, \"Cargo\"), (273317270, \"Fishing Vessel\"),\n",
    "    (273341920, \"Fishing Vessel\"), (273348570, \"Fishing Vessel\"), (273352280, \"Fishing Vessel\"),\n",
    "    (273392860, \"Fishing Vessel\"), (273415090, \"Fishing Vessel\"), (273428880, \"Fishing Vessel\"),\n",
    "    (273433630, \"Fishing Vessel\"), (273841710, \"Fishing Vessel\"), (273890200, \"Fishing Vessel\"),\n",
    "    (578001700, \"Passenger Ship\"), (257021000, \"Other Type\"), (257088020, \"Military Ops\"),\n",
    "    (257934000, \"Supply Ship\"), (258107000, \"Offshore Support Vessel\"), (258535000, \"Fishing Vessel\"),\n",
    "    (258828000, \"Pollution Control Vessel\"), (259987000, \"Passenger Ship\"), (273148810, \"Cargo\"),\n",
    "    (273391950, \"Fishing Vessel\"), (273418680, \"Fishing Vessel\"), (273430750, \"Fishing Vessel\"),\n",
    "    (276830000, \"Fishing Vessel\"), (224717000, \"Fishing Vessel\"), (257093370, \"Fishing Vessel\"),\n",
    "    (257095980, \"Passenger Ship\"), (257105000, \"Fishing Vessel\"), (258499000, \"Passenger Ship\"),\n",
    "    (259045000, \"Military Ops\"), (273213010, \"Fishing Vessel\"), (273213300, \"Fishing Vessel\"),\n",
    "    (273217010, \"Fishing Vessel\"), (273311280, \"Fishing Vessel\"), (273317810, \"Cargo\"),\n",
    "    (273332560, \"Fishing Vessel\"), (273351680, \"Fishing Vessel\"), (273398460, \"Fishing Vessel\"),\n",
    "    (273425330, \"Fishing Vessel\"), (273432340, \"Other Type\"), (273448380, \"Fishing Vessel\"),\n",
    "    (277558000, \"Fishing Vessel\"), (982570113, \"Other Type\"), (244820055, \"Cargo\"),\n",
    "    (273354540, \"Fishing Vessel\"), (273431440, \"Fishing Vessel\"), (273436210, \"Fishing Vessel\"),\n",
    "    (273437550, \"Fishing Vessel\"), (273439220, \"Research Vessel\"), (273550600, \"Fishing Vessel\"),\n",
    "    (231770000, \"Other Type\"), (257046460, \"Fishing Vessel\"), (257071530, \"Other Type\"),\n",
    "    (258874000, \"Fishing Vessel\"), (259616000, \"Fishing Vessel\"), (273380430, \"Fishing Vessel\"),\n",
    "    (273419350, \"Cargo\"), (273424080, \"Fishing Vessel\"), (273428090, \"Cargo\"),\n",
    "    (244810617, \"Cargo\"), (258186000, \"Fishing Vessel\"), (273355780, \"Fishing Vessel\"),\n",
    "    (273431310, \"Fishing Vessel\"), (257043030, \"Resolution 18\"), (257271600, \"Fishing Vessel\"),\n",
    "    (257508500, \"Other Type\"), (257656000, \"Fishing Vessel\"), (257806000, \"Fishing Vessel\"),\n",
    "    (273293480, \"Fishing Vessel\"), (273845800, \"Fishing Vessel\"), (273895100, \"Fishing Vessel\"),\n",
    "    (231219000, \"Passenger Ship\"), (259217000, \"Fishing Vessel\"), (273218630, \"Cargo\"),\n",
    "    (273537800, \"Fishing Vessel\"), (273891000, \"Fishing Vessel\")\n",
    "]\n",
    "\n",
    "\n",
    "general_categories = {\n",
    "    \"Tanker\": \"Commercial\",\n",
    "    \"Cargo\": \"Commercial\",\n",
    "    \"Supply Ship\": \"Commercial\",\n",
    "    \"Fishing Vessel\": \"Fishing\",\n",
    "    \"Yacht\": \"Recreational\",\n",
    "    \"Passenger Ship\": \"Passenger\",\n",
    "    \"HSC\": \"Passenger\",\n",
    "    \"Pleasure Craft\": \"Recreational\",\n",
    "    \"Sailing Vessel\": \"Recreational\",\n",
    "    \"Research Vessel\": \"Service\",\n",
    "    \"Patrol Vessel\": \"Service\",\n",
    "    \"Military Ops\": \"Service\",\n",
    "    \"Pilot\": \"Service\",\n",
    "    \"Port tender\": \"Service\",\n",
    "    \"Ice breaker\": \"Service\",\n",
    "    \"Lighthouse Vessel\": \"Special\",\n",
    "    \"Pollution Control Vessel\": \"Service\",\n",
    "    \"Offshore Support Vessel\": \"Service\",\n",
    "    \"Resolution 18 ship\": \"Other\",\n",
    "    \"Other Type\": \"Other\"\n",
    "}\n",
    "\n",
    "df_ships = pd.DataFrame(full_ship_data, columns=[\"mmsi\", \"Specific Type\"])\n",
    "df_ships['General Type'] = df_ships['Specific Type'].map(general_categories)\n",
    "\n",
    "df_ships\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
